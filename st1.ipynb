{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "SBIN_1HR = yf.download('SBIN.NS',interval='1h',period='2y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function macd in module pandas_ta.momentum.macd:\n",
      "\n",
      "macd(close, fast=None, slow=None, signal=None, talib=None, offset=None, **kwargs)\n",
      "    Moving Average Convergence Divergence (MACD)\n",
      "\n",
      "    The MACD is a popular indicator to that is used to identify a security's trend.\n",
      "    While APO and MACD are the same calculation, MACD also returns two more series\n",
      "    called Signal and Histogram. The Signal is an EMA of MACD and the Histogram is\n",
      "    the difference of MACD and Signal.\n",
      "\n",
      "    Sources:\n",
      "        https://www.tradingview.com/wiki/MACD_(Moving_Average_Convergence/Divergence)\n",
      "        AS Mode: https://tr.tradingview.com/script/YFlKXHnP/\n",
      "\n",
      "    Calculation:\n",
      "        Default Inputs:\n",
      "            fast=12, slow=26, signal=9\n",
      "        EMA = Exponential Moving Average\n",
      "        MACD = EMA(close, fast) - EMA(close, slow)\n",
      "        Signal = EMA(MACD, signal)\n",
      "        Histogram = MACD - Signal\n",
      "\n",
      "        if asmode:\n",
      "            MACD = MACD - Signal\n",
      "            Signal = EMA(MACD, signal)\n",
      "            Histogram = MACD - Signal\n",
      "\n",
      "    Args:\n",
      "        close (pd.Series): Series of 'close's\n",
      "        fast (int): The short period. Default: 12\n",
      "        slow (int): The long period. Default: 26\n",
      "        signal (int): The signal period. Default: 9\n",
      "        talib (bool): If TA Lib is installed and talib is True, Returns the TA Lib\n",
      "            version. Default: True\n",
      "        offset (int): How many periods to offset the result. Default: 0\n",
      "\n",
      "    Kwargs:\n",
      "        asmode (value, optional): When True, enables AS version of MACD.\n",
      "            Default: False\n",
      "        fillna (value, optional): pd.DataFrame.fillna(value)\n",
      "        fill_method (value, optional): Type of fill method\n",
      "\n",
      "    Returns:\n",
      "        pd.DataFrame: macd, histogram, signal columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ta.macd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBIN_1HR['RSI'] = ta.rsi(SBIN_1HR['Close'], length=14)\n",
    "#Calculate MACD\n",
    "\n",
    "SBIN_1HR['VWMA 20'] = ta.vwma(SBIN_1HR['Close'],volume=SBIN_1HR['Volume'], length=20)\n",
    "SBIN_1HR['VWMA 50'] = ta.vwma(SBIN_1HR['Close'],volume=SBIN_1HR['Volume'], length=50)\n",
    "SBIN_1HR['VWMA 200'] = ta.vwma(SBIN_1HR['Close'],volume=SBIN_1HR['Volume'], length=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MACD\n",
    "macd = SBIN_1HR.ta.macd(fast=12, slow=26, signal=9, mamode='ema')\n",
    "\n",
    "# Add the MACD components to new columns in the DataFrame\n",
    "SBIN_1HR['MACD'] = macd['MACD_12_26_9']\n",
    "SBIN_1HR['MACD_Signal'] = macd['MACDs_12_26_9']\n",
    "SBIN_1HR['MACD_Hist'] = macd['MACDh_12_26_9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slope(series,period:int = 5):\n",
    "    slopes = [0 for _ in range(period-1)]\n",
    "    for i in range(period-1,len(series)):\n",
    "        x = np.arange(period)\n",
    "        y = series[i-period+1:i+1].values\n",
    "        slope = np.polyfit(x,y,1)[0]\n",
    "        percent_slope = (slope/y[0]) *100\n",
    "        slopes.append(percent_slope)\n",
    "    return slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>VWMA 20</th>\n",
       "      <th>VWMA 50</th>\n",
       "      <th>VWMA 200</th>\n",
       "      <th>VWMA_20 Slope</th>\n",
       "      <th>VWMA_50 Slope</th>\n",
       "      <th>VWMA_200 Slope</th>\n",
       "      <th>Future_Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-22 09:15:00+05:30</th>\n",
       "      <td>566.900024</td>\n",
       "      <td>569.650024</td>\n",
       "      <td>564.599976</td>\n",
       "      <td>566.900024</td>\n",
       "      <td>566.900024</td>\n",
       "      <td>0</td>\n",
       "      <td>44.305562</td>\n",
       "      <td>572.015524</td>\n",
       "      <td>567.483592</td>\n",
       "      <td>540.505331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>566.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22 10:15:00+05:30</th>\n",
       "      <td>567.000000</td>\n",
       "      <td>568.400024</td>\n",
       "      <td>564.549988</td>\n",
       "      <td>566.599976</td>\n",
       "      <td>566.599976</td>\n",
       "      <td>1657373</td>\n",
       "      <td>43.811609</td>\n",
       "      <td>571.631091</td>\n",
       "      <td>567.463915</td>\n",
       "      <td>540.887285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22 11:15:00+05:30</th>\n",
       "      <td>566.700012</td>\n",
       "      <td>566.700012</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>2046404</td>\n",
       "      <td>39.683086</td>\n",
       "      <td>570.919977</td>\n",
       "      <td>567.519551</td>\n",
       "      <td>541.416341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>565.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22 12:15:00+05:30</th>\n",
       "      <td>563.950012</td>\n",
       "      <td>565.400024</td>\n",
       "      <td>562.000000</td>\n",
       "      <td>565.400024</td>\n",
       "      <td>565.400024</td>\n",
       "      <td>975955</td>\n",
       "      <td>42.808367</td>\n",
       "      <td>570.735985</td>\n",
       "      <td>567.669103</td>\n",
       "      <td>541.687407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>572.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22 13:15:00+05:30</th>\n",
       "      <td>565.400024</td>\n",
       "      <td>572.950012</td>\n",
       "      <td>565.150024</td>\n",
       "      <td>572.200012</td>\n",
       "      <td>572.200012</td>\n",
       "      <td>2342415</td>\n",
       "      <td>55.003485</td>\n",
       "      <td>570.583071</td>\n",
       "      <td>568.013085</td>\n",
       "      <td>541.960174</td>\n",
       "      <td>-0.065733</td>\n",
       "      <td>0.022277</td>\n",
       "      <td>0.068636</td>\n",
       "      <td>566.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 10:15:00+05:30</th>\n",
       "      <td>805.299988</td>\n",
       "      <td>812.450012</td>\n",
       "      <td>804.299988</td>\n",
       "      <td>811.250000</td>\n",
       "      <td>811.250000</td>\n",
       "      <td>2791913</td>\n",
       "      <td>42.957888</td>\n",
       "      <td>807.900429</td>\n",
       "      <td>832.156253</td>\n",
       "      <td>853.991441</td>\n",
       "      <td>-0.031188</td>\n",
       "      <td>-0.182781</td>\n",
       "      <td>-0.018317</td>\n",
       "      <td>816.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 11:15:00+05:30</th>\n",
       "      <td>811.200012</td>\n",
       "      <td>816.750000</td>\n",
       "      <td>811.200012</td>\n",
       "      <td>816.750000</td>\n",
       "      <td>816.750000</td>\n",
       "      <td>2538224</td>\n",
       "      <td>49.012619</td>\n",
       "      <td>808.223859</td>\n",
       "      <td>831.152912</td>\n",
       "      <td>853.915323</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>-0.152539</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>811.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 12:15:00+05:30</th>\n",
       "      <td>816.900024</td>\n",
       "      <td>817.799988</td>\n",
       "      <td>810.349976</td>\n",
       "      <td>811.299988</td>\n",
       "      <td>811.299988</td>\n",
       "      <td>1781582</td>\n",
       "      <td>44.025776</td>\n",
       "      <td>808.301579</td>\n",
       "      <td>830.180238</td>\n",
       "      <td>853.784304</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>-0.130591</td>\n",
       "      <td>-0.012227</td>\n",
       "      <td>809.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 13:15:00+05:30</th>\n",
       "      <td>811.299988</td>\n",
       "      <td>811.900024</td>\n",
       "      <td>807.049988</td>\n",
       "      <td>809.000000</td>\n",
       "      <td>809.000000</td>\n",
       "      <td>1503106</td>\n",
       "      <td>42.079942</td>\n",
       "      <td>808.076492</td>\n",
       "      <td>829.165090</td>\n",
       "      <td>853.615897</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>-0.136676</td>\n",
       "      <td>-0.016883</td>\n",
       "      <td>808.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 14:15:00+05:30</th>\n",
       "      <td>809.049988</td>\n",
       "      <td>811.599976</td>\n",
       "      <td>807.400024</td>\n",
       "      <td>808.299988</td>\n",
       "      <td>808.299988</td>\n",
       "      <td>2024425</td>\n",
       "      <td>41.479056</td>\n",
       "      <td>808.033242</td>\n",
       "      <td>828.368971</td>\n",
       "      <td>853.354303</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>-0.114911</td>\n",
       "      <td>-0.018428</td>\n",
       "      <td>808.049988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3220 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Datetime                                                                    \n",
       "2022-09-22 09:15:00+05:30  566.900024  569.650024  564.599976  566.900024   \n",
       "2022-09-22 10:15:00+05:30  567.000000  568.400024  564.549988  566.599976   \n",
       "2022-09-22 11:15:00+05:30  566.700012  566.700012  563.000000  564.000000   \n",
       "2022-09-22 12:15:00+05:30  563.950012  565.400024  562.000000  565.400024   \n",
       "2022-09-22 13:15:00+05:30  565.400024  572.950012  565.150024  572.200012   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-08-08 10:15:00+05:30  805.299988  812.450012  804.299988  811.250000   \n",
       "2024-08-08 11:15:00+05:30  811.200012  816.750000  811.200012  816.750000   \n",
       "2024-08-08 12:15:00+05:30  816.900024  817.799988  810.349976  811.299988   \n",
       "2024-08-08 13:15:00+05:30  811.299988  811.900024  807.049988  809.000000   \n",
       "2024-08-08 14:15:00+05:30  809.049988  811.599976  807.400024  808.299988   \n",
       "\n",
       "                            Adj Close   Volume        RSI     VWMA 20  \\\n",
       "Datetime                                                                \n",
       "2022-09-22 09:15:00+05:30  566.900024        0  44.305562  572.015524   \n",
       "2022-09-22 10:15:00+05:30  566.599976  1657373  43.811609  571.631091   \n",
       "2022-09-22 11:15:00+05:30  564.000000  2046404  39.683086  570.919977   \n",
       "2022-09-22 12:15:00+05:30  565.400024   975955  42.808367  570.735985   \n",
       "2022-09-22 13:15:00+05:30  572.200012  2342415  55.003485  570.583071   \n",
       "...                               ...      ...        ...         ...   \n",
       "2024-08-08 10:15:00+05:30  811.250000  2791913  42.957888  807.900429   \n",
       "2024-08-08 11:15:00+05:30  816.750000  2538224  49.012619  808.223859   \n",
       "2024-08-08 12:15:00+05:30  811.299988  1781582  44.025776  808.301579   \n",
       "2024-08-08 13:15:00+05:30  809.000000  1503106  42.079942  808.076492   \n",
       "2024-08-08 14:15:00+05:30  808.299988  2024425  41.479056  808.033242   \n",
       "\n",
       "                              VWMA 50    VWMA 200  VWMA_20 Slope  \\\n",
       "Datetime                                                           \n",
       "2022-09-22 09:15:00+05:30  567.483592  540.505331       0.000000   \n",
       "2022-09-22 10:15:00+05:30  567.463915  540.887285       0.000000   \n",
       "2022-09-22 11:15:00+05:30  567.519551  541.416341       0.000000   \n",
       "2022-09-22 12:15:00+05:30  567.669103  541.687407       0.000000   \n",
       "2022-09-22 13:15:00+05:30  568.013085  541.960174      -0.065733   \n",
       "...                               ...         ...            ...   \n",
       "2024-08-08 10:15:00+05:30  832.156253  853.991441      -0.031188   \n",
       "2024-08-08 11:15:00+05:30  831.152912  853.915323      -0.001856   \n",
       "2024-08-08 12:15:00+05:30  830.180238  853.784304       0.005770   \n",
       "2024-08-08 13:15:00+05:30  829.165090  853.615897       0.008227   \n",
       "2024-08-08 14:15:00+05:30  828.368971  853.354303       0.001464   \n",
       "\n",
       "                           VWMA_50 Slope  VWMA_200 Slope  Future_Close  \n",
       "Datetime                                                                \n",
       "2022-09-22 09:15:00+05:30       0.000000        0.000000    566.599976  \n",
       "2022-09-22 10:15:00+05:30       0.000000        0.000000    564.000000  \n",
       "2022-09-22 11:15:00+05:30       0.000000        0.000000    565.400024  \n",
       "2022-09-22 12:15:00+05:30       0.000000        0.000000    572.200012  \n",
       "2022-09-22 13:15:00+05:30       0.022277        0.068636    566.900024  \n",
       "...                                  ...             ...           ...  \n",
       "2024-08-08 10:15:00+05:30      -0.182781       -0.018317    816.750000  \n",
       "2024-08-08 11:15:00+05:30      -0.152539       -0.010336    811.299988  \n",
       "2024-08-08 12:15:00+05:30      -0.130591       -0.012227    809.000000  \n",
       "2024-08-08 13:15:00+05:30      -0.136676       -0.016883    808.299988  \n",
       "2024-08-08 14:15:00+05:30      -0.114911       -0.018428    808.049988  \n",
       "\n",
       "[3220 rows x 14 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBIN_1HR['VWMA_20 Slope'] = calculate_slope(SBIN_1HR['VWMA 20'])\n",
    "SBIN_1HR['VWMA_50 Slope'] = calculate_slope(SBIN_1HR['VWMA 50'])\n",
    "SBIN_1HR['VWMA_200 Slope'] = calculate_slope(SBIN_1HR['VWMA 200'])\n",
    "SBIN_1HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function bbands in module pandas_ta.volatility.bbands:\n",
      "\n",
      "bbands(close, length=None, std=None, ddof=0, mamode=None, talib=None, offset=None, **kwargs)\n",
      "    Bollinger Bands (BBANDS)\n",
      "\n",
      "    A popular volatility indicator by John Bollinger.\n",
      "\n",
      "    Sources:\n",
      "        https://www.tradingview.com/wiki/Bollinger_Bands_(BB)\n",
      "\n",
      "    Calculation:\n",
      "        Default Inputs:\n",
      "            length=5, std=2, mamode=\"sma\", ddof=0\n",
      "        EMA = Exponential Moving Average\n",
      "        SMA = Simple Moving Average\n",
      "        STDEV = Standard Deviation\n",
      "        stdev = STDEV(close, length, ddof)\n",
      "        if \"ema\":\n",
      "            MID = EMA(close, length)\n",
      "        else:\n",
      "            MID = SMA(close, length)\n",
      "\n",
      "        LOWER = MID - std * stdev\n",
      "        UPPER = MID + std * stdev\n",
      "\n",
      "        BANDWIDTH = 100 * (UPPER - LOWER) / MID\n",
      "        PERCENT = (close - LOWER) / (UPPER - LOWER)\n",
      "\n",
      "    Args:\n",
      "        close (pd.Series): Series of 'close's\n",
      "        length (int): The short period. Default: 5\n",
      "        std (int): The long period. Default: 2\n",
      "        ddof (int): Degrees of Freedom to use. Default: 0\n",
      "        mamode (str): See ```help(ta.ma)```. Default: 'sma'\n",
      "        talib (bool): If TA Lib is installed and talib is True, Returns the TA Lib\n",
      "            version. Default: True\n",
      "        offset (int): How many periods to offset the result. Default: 0\n",
      "\n",
      "    Kwargs:\n",
      "        fillna (value, optional): pd.DataFrame.fillna(value)\n",
      "        fill_method (value, optional): Type of fill method\n",
      "\n",
      "    Returns:\n",
      "        pd.DataFrame: lower, mid, upper, bandwidth, and percent columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ta.bbands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Bollinger Bands\n",
    "bbands = SBIN_1HR.ta.bbands(length=20, std=2, mamode='ema')\n",
    "\n",
    "# Assign the calculated Bollinger Bands to new columns in the DataFrame\n",
    "SBIN_1HR['BB_Lower'] = bbands['BBL_20_2.0']\n",
    "SBIN_1HR['BB_Middle'] = bbands['BBM_20_2.0']\n",
    "SBIN_1HR['BB_Upper'] = bbands['BBU_20_2.0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SBIN_1HR.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>VWMA 20</th>\n",
       "      <th>VWMA 50</th>\n",
       "      <th>VWMA 200</th>\n",
       "      <th>VWMA_20 Slope</th>\n",
       "      <th>VWMA_50 Slope</th>\n",
       "      <th>VWMA_200 Slope</th>\n",
       "      <th>Future_Close</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>BB_Lower</th>\n",
       "      <th>BB_Middle</th>\n",
       "      <th>BB_Upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-28 14:15:00+05:30</th>\n",
       "      <td>534.200012</td>\n",
       "      <td>534.549988</td>\n",
       "      <td>526.049988</td>\n",
       "      <td>526.500000</td>\n",
       "      <td>526.500000</td>\n",
       "      <td>2496708</td>\n",
       "      <td>26.923266</td>\n",
       "      <td>538.792523</td>\n",
       "      <td>553.992336</td>\n",
       "      <td>544.308930</td>\n",
       "      <td>-0.209174</td>\n",
       "      <td>-0.159872</td>\n",
       "      <td>-0.005295</td>\n",
       "      <td>523.700012</td>\n",
       "      <td>-7.312370</td>\n",
       "      <td>-7.118086</td>\n",
       "      <td>-0.194285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28 15:15:00+05:30</th>\n",
       "      <td>526.299988</td>\n",
       "      <td>526.599976</td>\n",
       "      <td>520.700012</td>\n",
       "      <td>523.700012</td>\n",
       "      <td>523.700012</td>\n",
       "      <td>1986616</td>\n",
       "      <td>24.986670</td>\n",
       "      <td>537.805691</td>\n",
       "      <td>552.269934</td>\n",
       "      <td>544.212700</td>\n",
       "      <td>-0.224691</td>\n",
       "      <td>-0.205607</td>\n",
       "      <td>-0.013357</td>\n",
       "      <td>530.900024</td>\n",
       "      <td>-7.775336</td>\n",
       "      <td>-7.249536</td>\n",
       "      <td>-0.525801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-29 09:15:00+05:30</th>\n",
       "      <td>529.000000</td>\n",
       "      <td>535.500000</td>\n",
       "      <td>528.900024</td>\n",
       "      <td>530.900024</td>\n",
       "      <td>530.900024</td>\n",
       "      <td>0</td>\n",
       "      <td>37.446803</td>\n",
       "      <td>538.058131</td>\n",
       "      <td>551.872039</td>\n",
       "      <td>544.246149</td>\n",
       "      <td>-0.176101</td>\n",
       "      <td>-0.209910</td>\n",
       "      <td>-0.012790</td>\n",
       "      <td>529.799988</td>\n",
       "      <td>-7.475091</td>\n",
       "      <td>-7.294647</td>\n",
       "      <td>-0.180444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-29 10:15:00+05:30</th>\n",
       "      <td>530.700012</td>\n",
       "      <td>531.799988</td>\n",
       "      <td>528.200012</td>\n",
       "      <td>529.799988</td>\n",
       "      <td>529.799988</td>\n",
       "      <td>1213873</td>\n",
       "      <td>36.450601</td>\n",
       "      <td>537.418777</td>\n",
       "      <td>551.449235</td>\n",
       "      <td>544.218408</td>\n",
       "      <td>-0.122633</td>\n",
       "      <td>-0.179530</td>\n",
       "      <td>-0.008924</td>\n",
       "      <td>524.950012</td>\n",
       "      <td>-7.242422</td>\n",
       "      <td>-7.284202</td>\n",
       "      <td>0.041779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-29 11:15:00+05:30</th>\n",
       "      <td>529.900024</td>\n",
       "      <td>530.250000</td>\n",
       "      <td>523.849976</td>\n",
       "      <td>524.950012</td>\n",
       "      <td>524.950012</td>\n",
       "      <td>2348483</td>\n",
       "      <td>32.362748</td>\n",
       "      <td>535.700949</td>\n",
       "      <td>550.065560</td>\n",
       "      <td>544.127950</td>\n",
       "      <td>-0.121940</td>\n",
       "      <td>-0.156577</td>\n",
       "      <td>-0.006545</td>\n",
       "      <td>523.849976</td>\n",
       "      <td>-7.364490</td>\n",
       "      <td>-7.300260</td>\n",
       "      <td>-0.064230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 09:15:00+05:30</th>\n",
       "      <td>806.599976</td>\n",
       "      <td>809.400024</td>\n",
       "      <td>802.799988</td>\n",
       "      <td>805.299988</td>\n",
       "      <td>805.299988</td>\n",
       "      <td>0</td>\n",
       "      <td>35.231704</td>\n",
       "      <td>807.944711</td>\n",
       "      <td>833.875620</td>\n",
       "      <td>854.233415</td>\n",
       "      <td>-0.091934</td>\n",
       "      <td>-0.229137</td>\n",
       "      <td>-0.025853</td>\n",
       "      <td>811.250000</td>\n",
       "      <td>-9.640289</td>\n",
       "      <td>-11.864876</td>\n",
       "      <td>2.224588</td>\n",
       "      <td>803.092261</td>\n",
       "      <td>813.081158</td>\n",
       "      <td>823.070054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 10:15:00+05:30</th>\n",
       "      <td>805.299988</td>\n",
       "      <td>812.450012</td>\n",
       "      <td>804.299988</td>\n",
       "      <td>811.250000</td>\n",
       "      <td>811.250000</td>\n",
       "      <td>2791913</td>\n",
       "      <td>42.957888</td>\n",
       "      <td>807.900429</td>\n",
       "      <td>832.156253</td>\n",
       "      <td>853.991441</td>\n",
       "      <td>-0.031188</td>\n",
       "      <td>-0.182781</td>\n",
       "      <td>-0.018317</td>\n",
       "      <td>816.750000</td>\n",
       "      <td>-8.659612</td>\n",
       "      <td>-11.223823</td>\n",
       "      <td>2.564212</td>\n",
       "      <td>802.881682</td>\n",
       "      <td>812.906762</td>\n",
       "      <td>822.931842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 11:15:00+05:30</th>\n",
       "      <td>811.200012</td>\n",
       "      <td>816.750000</td>\n",
       "      <td>811.200012</td>\n",
       "      <td>816.750000</td>\n",
       "      <td>816.750000</td>\n",
       "      <td>2538224</td>\n",
       "      <td>49.012619</td>\n",
       "      <td>808.223859</td>\n",
       "      <td>831.152912</td>\n",
       "      <td>853.915323</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>-0.152539</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>811.299988</td>\n",
       "      <td>-7.353844</td>\n",
       "      <td>-10.449827</td>\n",
       "      <td>3.095984</td>\n",
       "      <td>802.561360</td>\n",
       "      <td>813.272784</td>\n",
       "      <td>823.984209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 12:15:00+05:30</th>\n",
       "      <td>816.900024</td>\n",
       "      <td>817.799988</td>\n",
       "      <td>810.349976</td>\n",
       "      <td>811.299988</td>\n",
       "      <td>811.299988</td>\n",
       "      <td>1781582</td>\n",
       "      <td>44.025776</td>\n",
       "      <td>808.301579</td>\n",
       "      <td>830.180238</td>\n",
       "      <td>853.784304</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>-0.130591</td>\n",
       "      <td>-0.012227</td>\n",
       "      <td>809.000000</td>\n",
       "      <td>-6.681760</td>\n",
       "      <td>-9.696214</td>\n",
       "      <td>3.014454</td>\n",
       "      <td>802.296238</td>\n",
       "      <td>813.084899</td>\n",
       "      <td>823.873560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 13:15:00+05:30</th>\n",
       "      <td>811.299988</td>\n",
       "      <td>811.900024</td>\n",
       "      <td>807.049988</td>\n",
       "      <td>809.000000</td>\n",
       "      <td>809.000000</td>\n",
       "      <td>1503106</td>\n",
       "      <td>42.079942</td>\n",
       "      <td>808.076492</td>\n",
       "      <td>829.165090</td>\n",
       "      <td>853.615897</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>-0.136676</td>\n",
       "      <td>-0.016883</td>\n",
       "      <td>808.299988</td>\n",
       "      <td>-6.262529</td>\n",
       "      <td>-9.009477</td>\n",
       "      <td>2.746948</td>\n",
       "      <td>802.021782</td>\n",
       "      <td>812.695861</td>\n",
       "      <td>823.369940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3186 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Datetime                                                                    \n",
       "2022-09-28 14:15:00+05:30  534.200012  534.549988  526.049988  526.500000   \n",
       "2022-09-28 15:15:00+05:30  526.299988  526.599976  520.700012  523.700012   \n",
       "2022-09-29 09:15:00+05:30  529.000000  535.500000  528.900024  530.900024   \n",
       "2022-09-29 10:15:00+05:30  530.700012  531.799988  528.200012  529.799988   \n",
       "2022-09-29 11:15:00+05:30  529.900024  530.250000  523.849976  524.950012   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-08-08 09:15:00+05:30  806.599976  809.400024  802.799988  805.299988   \n",
       "2024-08-08 10:15:00+05:30  805.299988  812.450012  804.299988  811.250000   \n",
       "2024-08-08 11:15:00+05:30  811.200012  816.750000  811.200012  816.750000   \n",
       "2024-08-08 12:15:00+05:30  816.900024  817.799988  810.349976  811.299988   \n",
       "2024-08-08 13:15:00+05:30  811.299988  811.900024  807.049988  809.000000   \n",
       "\n",
       "                            Adj Close   Volume        RSI     VWMA 20  \\\n",
       "Datetime                                                                \n",
       "2022-09-28 14:15:00+05:30  526.500000  2496708  26.923266  538.792523   \n",
       "2022-09-28 15:15:00+05:30  523.700012  1986616  24.986670  537.805691   \n",
       "2022-09-29 09:15:00+05:30  530.900024        0  37.446803  538.058131   \n",
       "2022-09-29 10:15:00+05:30  529.799988  1213873  36.450601  537.418777   \n",
       "2022-09-29 11:15:00+05:30  524.950012  2348483  32.362748  535.700949   \n",
       "...                               ...      ...        ...         ...   \n",
       "2024-08-08 09:15:00+05:30  805.299988        0  35.231704  807.944711   \n",
       "2024-08-08 10:15:00+05:30  811.250000  2791913  42.957888  807.900429   \n",
       "2024-08-08 11:15:00+05:30  816.750000  2538224  49.012619  808.223859   \n",
       "2024-08-08 12:15:00+05:30  811.299988  1781582  44.025776  808.301579   \n",
       "2024-08-08 13:15:00+05:30  809.000000  1503106  42.079942  808.076492   \n",
       "\n",
       "                              VWMA 50    VWMA 200  VWMA_20 Slope  \\\n",
       "Datetime                                                           \n",
       "2022-09-28 14:15:00+05:30  553.992336  544.308930      -0.209174   \n",
       "2022-09-28 15:15:00+05:30  552.269934  544.212700      -0.224691   \n",
       "2022-09-29 09:15:00+05:30  551.872039  544.246149      -0.176101   \n",
       "2022-09-29 10:15:00+05:30  551.449235  544.218408      -0.122633   \n",
       "2022-09-29 11:15:00+05:30  550.065560  544.127950      -0.121940   \n",
       "...                               ...         ...            ...   \n",
       "2024-08-08 09:15:00+05:30  833.875620  854.233415      -0.091934   \n",
       "2024-08-08 10:15:00+05:30  832.156253  853.991441      -0.031188   \n",
       "2024-08-08 11:15:00+05:30  831.152912  853.915323      -0.001856   \n",
       "2024-08-08 12:15:00+05:30  830.180238  853.784304       0.005770   \n",
       "2024-08-08 13:15:00+05:30  829.165090  853.615897       0.008227   \n",
       "\n",
       "                           VWMA_50 Slope  VWMA_200 Slope  Future_Close  \\\n",
       "Datetime                                                                 \n",
       "2022-09-28 14:15:00+05:30      -0.159872       -0.005295    523.700012   \n",
       "2022-09-28 15:15:00+05:30      -0.205607       -0.013357    530.900024   \n",
       "2022-09-29 09:15:00+05:30      -0.209910       -0.012790    529.799988   \n",
       "2022-09-29 10:15:00+05:30      -0.179530       -0.008924    524.950012   \n",
       "2022-09-29 11:15:00+05:30      -0.156577       -0.006545    523.849976   \n",
       "...                                  ...             ...           ...   \n",
       "2024-08-08 09:15:00+05:30      -0.229137       -0.025853    811.250000   \n",
       "2024-08-08 10:15:00+05:30      -0.182781       -0.018317    816.750000   \n",
       "2024-08-08 11:15:00+05:30      -0.152539       -0.010336    811.299988   \n",
       "2024-08-08 12:15:00+05:30      -0.130591       -0.012227    809.000000   \n",
       "2024-08-08 13:15:00+05:30      -0.136676       -0.016883    808.299988   \n",
       "\n",
       "                               MACD  MACD_Signal  MACD_Hist    BB_Lower  \\\n",
       "Datetime                                                                  \n",
       "2022-09-28 14:15:00+05:30 -7.312370    -7.118086  -0.194285         NaN   \n",
       "2022-09-28 15:15:00+05:30 -7.775336    -7.249536  -0.525801         NaN   \n",
       "2022-09-29 09:15:00+05:30 -7.475091    -7.294647  -0.180444         NaN   \n",
       "2022-09-29 10:15:00+05:30 -7.242422    -7.284202   0.041779         NaN   \n",
       "2022-09-29 11:15:00+05:30 -7.364490    -7.300260  -0.064230         NaN   \n",
       "...                             ...          ...        ...         ...   \n",
       "2024-08-08 09:15:00+05:30 -9.640289   -11.864876   2.224588  803.092261   \n",
       "2024-08-08 10:15:00+05:30 -8.659612   -11.223823   2.564212  802.881682   \n",
       "2024-08-08 11:15:00+05:30 -7.353844   -10.449827   3.095984  802.561360   \n",
       "2024-08-08 12:15:00+05:30 -6.681760    -9.696214   3.014454  802.296238   \n",
       "2024-08-08 13:15:00+05:30 -6.262529    -9.009477   2.746948  802.021782   \n",
       "\n",
       "                            BB_Middle    BB_Upper  \n",
       "Datetime                                           \n",
       "2022-09-28 14:15:00+05:30         NaN         NaN  \n",
       "2022-09-28 15:15:00+05:30         NaN         NaN  \n",
       "2022-09-29 09:15:00+05:30         NaN         NaN  \n",
       "2022-09-29 10:15:00+05:30         NaN         NaN  \n",
       "2022-09-29 11:15:00+05:30         NaN         NaN  \n",
       "...                               ...         ...  \n",
       "2024-08-08 09:15:00+05:30  813.081158  823.070054  \n",
       "2024-08-08 10:15:00+05:30  812.906762  822.931842  \n",
       "2024-08-08 11:15:00+05:30  813.272784  823.984209  \n",
       "2024-08-08 12:15:00+05:30  813.084899  823.873560  \n",
       "2024-08-08 13:15:00+05:30  812.695861  823.369940  \n",
       "\n",
       "[3186 rows x 20 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBIN_1HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/suganesh/New Volume/Trading_codes/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 417101.6875 - mae: 637.3675 - val_loss: 361653.5312 - val_mae: 594.1240\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 274239.6250 - mae: 504.9033 - val_loss: 41266.5586 - val_mae: 175.8163\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46409.0625 - mae: 176.0740 - val_loss: 28229.6406 - val_mae: 140.2064\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35376.9766 - mae: 154.7395 - val_loss: 22871.2012 - val_mae: 125.1854\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31009.7734 - mae: 142.3072 - val_loss: 18145.8516 - val_mae: 111.4053\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25210.9121 - mae: 128.5913 - val_loss: 14220.1846 - val_mae: 97.8933\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20859.2285 - mae: 118.0783 - val_loss: 10537.3398 - val_mae: 83.5561\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17115.6953 - mae: 105.1324 - val_loss: 7108.9150 - val_mae: 67.7850\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12583.0586 - mae: 88.7285 - val_loss: 4695.3550 - val_mae: 54.9212\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10590.7617 - mae: 81.7295 - val_loss: 3237.2913 - val_mae: 46.4438\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8506.2217 - mae: 72.0129 - val_loss: 2145.3804 - val_mae: 36.1738\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7916.0283 - mae: 70.7325 - val_loss: 1683.0673 - val_mae: 32.0463\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7013.6880 - mae: 65.7044 - val_loss: 1202.4861 - val_mae: 27.6912\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7095.4033 - mae: 66.9795 - val_loss: 925.6416 - val_mae: 24.1618\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6871.4731 - mae: 64.0937 - val_loss: 689.6840 - val_mae: 20.6774\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6459.8198 - mae: 63.1533 - val_loss: 509.1157 - val_mae: 17.1884\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6125.2705 - mae: 61.4165 - val_loss: 540.1768 - val_mae: 18.1120\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5890.2485 - mae: 60.6025 - val_loss: 630.8184 - val_mae: 20.2130\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5685.9736 - mae: 59.4577 - val_loss: 472.0002 - val_mae: 16.1460\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6261.5503 - mae: 61.6768 - val_loss: 359.4811 - val_mae: 13.6327\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6190.1768 - mae: 61.6712 - val_loss: 303.8024 - val_mae: 12.1090\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5620.8726 - mae: 60.0152 - val_loss: 454.2896 - val_mae: 16.9289\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5332.7334 - mae: 57.0371 - val_loss: 475.6632 - val_mae: 16.9313\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5503.1558 - mae: 58.6923 - val_loss: 257.1512 - val_mae: 11.2126\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5541.8525 - mae: 58.6413 - val_loss: 310.2947 - val_mae: 11.7977\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5524.8828 - mae: 57.3513 - val_loss: 271.4008 - val_mae: 13.0291\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5906.9839 - mae: 60.6474 - val_loss: 204.3643 - val_mae: 9.8919\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5721.5171 - mae: 58.7647 - val_loss: 189.2800 - val_mae: 9.6941\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5704.9478 - mae: 59.1650 - val_loss: 397.1831 - val_mae: 17.2223\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5644.5952 - mae: 58.3657 - val_loss: 146.9970 - val_mae: 7.7465\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5291.0522 - mae: 57.0489 - val_loss: 1215.0381 - val_mae: 29.7532\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5189.0884 - mae: 57.3063 - val_loss: 274.5112 - val_mae: 11.6907\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5070.0801 - mae: 55.7483 - val_loss: 407.6822 - val_mae: 17.2983\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5041.0010 - mae: 55.8807 - val_loss: 217.7832 - val_mae: 10.2163\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4732.1831 - mae: 55.0950 - val_loss: 419.9631 - val_mae: 15.7387\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4862.2456 - mae: 55.7238 - val_loss: 167.2463 - val_mae: 10.0339\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5497.1021 - mae: 59.0553 - val_loss: 498.9561 - val_mae: 19.9518\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4712.2695 - mae: 54.6557 - val_loss: 453.2050 - val_mae: 18.8652\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5062.3730 - mae: 55.3193 - val_loss: 167.4345 - val_mae: 9.1355\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5167.9189 - mae: 56.6010 - val_loss: 174.7170 - val_mae: 9.7504\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4913.7280 - mae: 54.4802 - val_loss: 204.6250 - val_mae: 11.5144\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5313.8164 - mae: 57.1801 - val_loss: 190.6965 - val_mae: 9.3169\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5126.9917 - mae: 55.5170 - val_loss: 162.6113 - val_mae: 9.0767\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5157.1372 - mae: 56.3066 - val_loss: 84.5144 - val_mae: 5.9334\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5093.0947 - mae: 55.7984 - val_loss: 184.4871 - val_mae: 11.2668\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5036.2754 - mae: 55.0323 - val_loss: 503.2023 - val_mae: 16.4574\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4714.5757 - mae: 54.6493 - val_loss: 167.0696 - val_mae: 10.0066\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4983.1372 - mae: 55.4559 - val_loss: 416.7948 - val_mae: 17.9306\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4799.2241 - mae: 54.0429 - val_loss: 102.4152 - val_mae: 7.3533\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4967.5107 - mae: 56.1999 - val_loss: 219.9625 - val_mae: 12.8879\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 194.9137 - mae: 12.3207\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Test Loss (MSE): 200.07217407226562\n",
      "Test Mean Absolute Error (MAE): 12.5971040725708\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Load your data\n",
    "sbin_data = SBIN_1HR\n",
    "\n",
    "# Create a target variable for future price prediction (e.g., price after 1 hour)\n",
    "sbin_data['Future_Close'] = sbin_data['Close'].shift(-1)\n",
    "\n",
    "# Drop any rows with missing values to avoid issues during model training\n",
    "sbin_data.dropna(inplace=True)\n",
    "\n",
    "# Select features for the model (indicators and slopes)\n",
    "features = ['RSI', 'VWMA 20', 'VWMA 50', 'VWMA 200', 'VWMA_20 Slope', 'VWMA_50 Slope', 'VWMA_200 Slope', \n",
    "             'BB_Upper', 'BB_Lower']\n",
    "\n",
    "# Prepare the feature matrix (X) and target vector (y)\n",
    "X = sbin_data[features]\n",
    "y = sbin_data['Future_Close']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dense(1)  # Output layer with one neuron for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"Test Loss (MSE): {test_loss}\")\n",
    "print(f\"Test Mean Absolute Error (MAE): {test_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/suganesh/New Volume/Trading_codes/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 418722.2188 - mae: 638.7297 - val_loss: 419635.3750 - val_mae: 638.9706 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 406117.7500 - mae: 629.6924 - val_loss: 390593.7500 - val_mae: 617.9708 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 357774.2500 - mae: 592.8701 - val_loss: 326722.0312 - val_mae: 566.7457 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 274812.3438 - mae: 520.3916 - val_loss: 237147.3125 - val_mae: 483.1722 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 186293.7812 - mae: 423.4720 - val_loss: 140450.2031 - val_mae: 366.5052 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 107515.6172 - mae: 306.0467 - val_loss: 73436.2969 - val_mae: 238.1842 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 60082.4570 - mae: 206.9197 - val_loss: 44984.0664 - val_mae: 157.1075 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41773.9102 - mae: 153.3835 - val_loss: 33211.8359 - val_mae: 130.5249 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34201.0938 - mae: 136.7218 - val_loss: 27345.9141 - val_mae: 116.3888 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32636.7227 - mae: 137.3211 - val_loss: 23105.7949 - val_mae: 103.9481 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26619.1504 - mae: 123.1037 - val_loss: 19571.4766 - val_mae: 85.4087 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24064.5645 - mae: 114.9512 - val_loss: 16828.9043 - val_mae: 76.9086 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22349.4141 - mae: 114.5216 - val_loss: 13536.7061 - val_mae: 71.5681 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24669.7246 - mae: 121.9514 - val_loss: 11141.2246 - val_mae: 63.5868 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18619.3633 - mae: 107.0012 - val_loss: 8915.9766 - val_mae: 57.8974 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14238.4316 - mae: 94.0554 - val_loss: 6420.4116 - val_mae: 47.4231 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15257.3516 - mae: 97.7739 - val_loss: 4486.6968 - val_mae: 44.2015 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11921.1631 - mae: 87.9838 - val_loss: 2498.6855 - val_mae: 34.5124 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12249.1582 - mae: 89.2871 - val_loss: 1718.0321 - val_mae: 27.3232 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10070.4688 - mae: 80.9893 - val_loss: 1503.1221 - val_mae: 24.2575 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9839.3311 - mae: 80.2444 - val_loss: 1193.4192 - val_mae: 21.4402 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9684.0918 - mae: 78.4689 - val_loss: 1235.4670 - val_mae: 21.7245 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7619.4180 - mae: 69.9194 - val_loss: 896.2119 - val_mae: 18.8806 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7096.3105 - mae: 66.6549 - val_loss: 954.9510 - val_mae: 21.1367 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8789.6602 - mae: 74.7268 - val_loss: 815.5397 - val_mae: 17.9384 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7690.7266 - mae: 69.2274 - val_loss: 1010.0088 - val_mae: 22.5846 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7090.5195 - mae: 67.4884 - val_loss: 779.4321 - val_mae: 17.0093 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7743.2974 - mae: 70.0781 - val_loss: 791.1941 - val_mae: 17.2989 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6973.0166 - mae: 66.0801 - val_loss: 677.3295 - val_mae: 14.8060 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6335.6191 - mae: 62.5619 - val_loss: 602.0095 - val_mae: 14.1244 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6139.5161 - mae: 61.5439 - val_loss: 587.8165 - val_mae: 16.5161 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5684.4736 - mae: 60.0780 - val_loss: 586.6880 - val_mae: 17.2960 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5794.6836 - mae: 60.4542 - val_loss: 587.6840 - val_mae: 16.3113 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6899.1670 - mae: 66.2556 - val_loss: 887.5244 - val_mae: 21.0989 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5788.7993 - mae: 61.9833 - val_loss: 750.9382 - val_mae: 18.3976 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5831.1670 - mae: 59.9971 - val_loss: 645.0018 - val_mae: 17.6737 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5706.7715 - mae: 60.4693 - val_loss: 605.2260 - val_mae: 17.6672 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[lr_reduction, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/suganesh/New Volume/Trading_codes/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m64\u001b[39m,(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m),activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n",
      "File \u001b[0;32m/media/suganesh/New Volume/Trading_codes/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py:120\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers\u001b[38;5;241m.\u001b[39mappend(layer)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/media/suganesh/New Volume/Trading_codes/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py:139\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    138\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/suganesh/New Volume/Trading_codes/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py:225\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    224\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 225\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m/media/suganesh/New Volume/Trading_codes/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py:183\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/media/suganesh/New Volume/Trading_codes/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/media/suganesh/New Volume/Trading_codes/.venv/lib/python3.12/site-packages/keras/src/layers/input_spec.py:202\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmin_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    204\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         )\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 1)"
     ]
    }
   ],
   "source": [
    "model.add(\n",
    "    Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(X_train.shape[1],),)\n",
    ")\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
